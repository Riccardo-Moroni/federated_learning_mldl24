{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSmFOKMBMTjP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.ops import MLP\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR100, CIFAR10, MNIST\n",
        "from torch.optim import SGD, lr_scheduler\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWh1Xx1WqXbk"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWbdX1IWUoSL",
        "outputId": "25c9209e-05d7-4656-bebc-7ae34afa144b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoAZ8gOdacB5",
        "outputId": "82e50943-2011-4eee-e6bd-26942205357f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to datasets/cifar100/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:13<00:00, 12847639.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datasets/cifar100/cifar-100-python.tar.gz to datasets/cifar100\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.RandomCrop((24, 24)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR100('datasets/cifar100', train=True, transform=preprocess, download=True)\n",
        "test_dataset = CIFAR100('datasets/cifar100', train=False, transform=preprocess, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMCoMOlAqhoy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCFyReyRRmzH"
      },
      "outputs": [],
      "source": [
        "class LeNet5_circa(nn.Module):\n",
        "    def __init__(self):\n",
        "        super( LeNet5_circa, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(576, 384)\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.fc3 = nn.Linear(192, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.conv1(x).relu())\n",
        "        x = self.pool(self.conv2(x).relu())\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x).relu()\n",
        "        x = self.fc2(x).relu()\n",
        "        x = self.fc3(x)\n",
        "        x = nn.functional.softmax(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = LeNet5_circa().cuda()\n",
        "model.to('cuda')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScpzaCYmLMJp",
        "outputId": "b9de9cc3-2e35-4c5d-b1d7-ff9e3533417e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet5_circa(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=576, out_features=384, bias=True)\n",
              "  (fc2): Linear(in_features=384, out_features=192, bias=True)\n",
              "  (fc3): Linear(in_features=192, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "backup = 1500\n",
        "if backup:\n",
        "    model.load_state_dict(torch.load(f'/content/drive/My Drive/lenet001-{backup}.pt'))\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3HCdQRYqe5f"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RNbgaj0TNS4"
      },
      "outputs": [],
      "source": [
        "T = 2000\n",
        "test_freq = 20\n",
        "save_freq = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUnGzbKJZscB",
        "outputId": "a05f13e6-89dd-451e-ecff-0f9049e01037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/500 [00:00<?, ?it/s]<ipython-input-4-8733bf8259b3>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = nn.functional.softmax(x)\n",
            "  0%|          | 1/500 [00:24<3:20:01, 24.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4.478512 Acc: 14.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 21/500 [07:02<2:46:10, 20.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4.475781 Acc: 14.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 41/500 [13:40<2:40:53, 21.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4.477677 Acc: 14.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 61/500 [20:21<2:33:47, 21.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4.478799 Acc: 14.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 81/500 [27:02<2:27:14, 21.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4.476023 Acc: 14.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 101/500 [33:48<2:20:09, 21.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4.476896 Acc: 14.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 121/500 [40:26<2:10:59, 20.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4.479036 Acc: 14.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 141/500 [47:05<2:04:37, 20.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4.480172 Acc: 14.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 161/500 [53:46<1:58:49, 21.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4.476419 Acc: 14.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 174/500 [58:05<1:50:02, 20.25s/it]"
          ]
        }
      ],
      "source": [
        "def test(model):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    test_accuracy = 100. * correct / total\n",
        "    print(f'Test Loss: {test_loss:.6f} Acc: {test_accuracy:.2f}%')\n",
        "    return test_accuracy, test_loss\n",
        "\n",
        "\n",
        "def train(model):\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "    for t in tqdm(range(backup, T)):\n",
        "        model.train()\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        if t % test_freq == 0 or t == T-1:\n",
        "            acc, loss = test(model)\n",
        "            accuracies.append(acc)\n",
        "            losses.append(loss)\n",
        "\n",
        "        if t % save_freq == 0 or t == T-1:\n",
        "            torch.save(model.state_dict(), f'/content/drive/My Drive/lenet001-{t}.pt')\n",
        "\n",
        "\n",
        "    return accuracies, losses\n",
        "\n",
        "\n",
        "accuracies, losses = train(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1qwWM9oUxUD"
      },
      "outputs": [],
      "source": [
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "xx = np.arange(0, T + test_freq, test_freq)\n",
        "plt.plot(xx, accuracies, label='centralized', marker='.')\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}