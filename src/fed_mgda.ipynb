{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAsOalFvQUDE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import CIFAR100\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "from client_selector import ClientSelector\n",
    "from data_splitter import DataSplitter\n",
    "from scipy.optimize import minimize, LinearConstraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "pXtnMBC7QVmh",
    "outputId": "870ef024-75d5-4e18-cd0d-b9d0e561d336"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiuwTfpqQRdH"
   },
   "outputs": [],
   "source": [
    "K = 100\n",
    "\n",
    "params = {\n",
    "    'K': K,\n",
    "    'C': 0.1,\n",
    "    'B': 64,\n",
    "    'J': 4,\n",
    "    'lr_server': 1,\n",
    "    'lr_client': 1e-1,\n",
    "    'participation': 'uniform',\n",
    "    'gamma': 1,\n",
    "    'rounds': 2000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rj87Xi-XRFiN",
    "outputId": "c1f738db-7ddd-434f-8caa-d38c2ce8fa6a"
   },
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.RandomCrop((28, 28)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR100('datasets/cifar100', train=True, transform=preprocess, download=True)\n",
    "test_dataset = CIFAR100('datasets/cifar100', train=False, transform=preprocess, download=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qo6gYjz9Q8j5",
    "outputId": "3361eee8-256d-4617-ab57-3900dc634999"
   },
   "outputs": [],
   "source": [
    "data_split_params = {\n",
    "    'K': K,\n",
    "    'split_method': 'non-iid',\n",
    "    'n_labels': 10\n",
    "}\n",
    "\n",
    "data_splitter = DataSplitter(data_split_params, train_dataset)\n",
    "client_datasets = data_splitter.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjjJ61U6Qonw"
   },
   "outputs": [],
   "source": [
    "client_selector = ClientSelector(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xz43NFMiQ5jJ"
   },
   "outputs": [],
   "source": [
    "class LeNet5_circa(nn.Module):\n",
    "    def __init__(self):\n",
    "        super( LeNet5_circa, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 64, 384)\n",
    "        self.fc2 = nn.Linear(384, 192)\n",
    "        self.fc3 = nn.Linear(192, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x).relu())\n",
    "        x = self.pool(self.conv2(x).relu())\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x).relu()\n",
    "        x = self.fc2(x).relu()\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = LeNet5_circa().cuda()\n",
    "model.to('cuda')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450,
     "referenced_widgets": [
      "7973b9bc3a64446cadd1dd22ef432ce0",
      "14489bc6b84f46839d1398c4e23f5001",
      "d60fae4b1f3b4fbd961c051e020ba102",
      "1288fecee38c44c5be5c626c4d83dbfb",
      "b9f10ca884164dfabc89f77b4310f0fa",
      "45cc15f7ffe2483eb8bff06634fdaaa5",
      "24beb4f068484d61a0c5213f73ae43d1",
      "db724347ab3040008122494925b38fd9"
     ]
    },
    "id": "PRDb3QHORQct",
    "outputId": "6f37035d-13ee-4775-84e5-b56fc07e0fe7"
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project='fl',\n",
    "    name=f'fed mgda {data_split_params[\"split_method\"]}, J={params[\"J\"]}, lr={params[\"lr_client\"]}, lr_server={params[\"lr_server\"]}, n_labels={data_split_params[\"n_labels\"]}',\n",
    "    config={**params, **data_split_params}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_biy7HgQyxM"
   },
   "outputs": [],
   "source": [
    "def w_norm(coeffs, clients_gradients_normalized):\n",
    "    w = np.sum([coeffs[i]*clients_gradients_normalized[i] for i in range(len(clients_gradients_normalized))], axis=0)\n",
    "    w_l2_norm = np.linalg.norm(w)\n",
    "    gradients = [2 * w.dot(clients_gradients_normalized[i]) for i in range(len(clients_gradients_normalized))]\n",
    "    return w_l2_norm, gradients\n",
    "\n",
    "def magical_gradient(clients_gradients):\n",
    "    n = len(clients_gradients)\n",
    "    coeffs = np.full(n, 1/n)\n",
    "\n",
    "    clients_gradients = list(clients_gradients)  # Convert generator to list\n",
    "\n",
    "    res = minimize(\n",
    "        w_norm,\n",
    "        coeffs,\n",
    "        args = (clients_gradients,),\n",
    "        jac=True,\n",
    "        bounds=[(0.,1.) for _ in range(n)],\n",
    "        constraints=[LinearConstraint(A=[[1] * n], lb = 1., ub = 1.)]\n",
    "    )\n",
    "\n",
    "    # this is the gradient produced by the minimization of the convex linear combination (so it's the shortest convex linear combination)\n",
    "    grad_mo = torch.tensor(sum(res.x[i]*clients_gradients[i] for i in range(n))).cuda()\n",
    "    return grad_mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = params['rounds']\n",
    "test_freq = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0G9B6yZQq1a",
    "outputId": "76ba1c3e-553f-4147-f8bf-f02a6de10472"
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = 100. * correct / total\n",
    "    print(f'Test Loss: {test_loss:.6f} Acc: {test_accuracy:.2f}%')\n",
    "    return test_accuracy, test_loss\n",
    "\n",
    "def client_update(model, k, params):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=params['lr_client'], weight_decay=4e-4)\n",
    "    loader = DataLoader(client_datasets[k], batch_size=params['B'], shuffle=True)\n",
    "\n",
    "    client_loss, client_correct, client_total = 0, 0, 0\n",
    "    i = 0\n",
    "    client_gradients = []\n",
    "    for i in range(params['J']):\n",
    "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            client_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            client_total += targets.size(0)\n",
    "            client_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # extract the gradient\n",
    "            client_grad = []\n",
    "            for parameter in model.parameters():\n",
    "                client_grad += parameter.grad.reshape(-1).tolist()\n",
    "            client_grad = np.array(client_grad)\n",
    "\n",
    "            client_gradients.append(client_grad)\n",
    "\n",
    "            optimizer.step()\n",
    "            i += 1\n",
    "\n",
    "            if i >= params['J']:\n",
    "                client_loss = client_loss / params['J']\n",
    "                client_accuracy = 100. * client_correct / client_total\n",
    "\n",
    "                client_gradients = np.array(client_gradients)\n",
    "                client_gradient_avg = np.mean(client_gradients, axis = 0) # average the gradients of the different J steps\n",
    "                client_gradient_norm = client_gradient_avg / np.linalg.norm(client_gradient_avg)\n",
    "\n",
    "                return client_accuracy, client_loss, client_gradient_norm\n",
    "\n",
    "    client_gradients = np.array(client_gradients)\n",
    "    client_gradient_avg = np.mean(client_gradients, axis = 0) # average the gradients of the different J steps\n",
    "    client_gradient_norm = client_gradient_avg / np.linalg.norm(client_gradient_avg)\n",
    "\n",
    "    client_loss = client_loss / params['J'] # average loss in J steps\n",
    "    client_accuracy = 100. * client_correct / client_total\n",
    "\n",
    "    return client_accuracy, client_loss, client_gradient_norm\n",
    "\n",
    "def train(model, params):\n",
    "    server_optimizer = SGD(model.parameters(), lr=params['lr_server'], weight_decay=4e-4)\n",
    "    server_optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    test_accuracies, test_losses = [], []\n",
    "    train_accuracies, train_losses = [], []\n",
    "\n",
    "    for t in tqdm(range(params['rounds'])):\n",
    "        round_loss, round_accuracy = 0, 0\n",
    "        s = client_selector.sample()\n",
    "\n",
    "        clients_grad_normalized = []\n",
    "        for k in s:\n",
    "            client_accuracy, client_loss, client_gradient_norm = client_update(copy.deepcopy(model), k, params)\n",
    "            round_loss += client_loss\n",
    "            round_accuracy += client_accuracy\n",
    "            clients_grad_normalized.append(client_gradient_norm)\n",
    "        round_loss_avg = round_loss / len(s)\n",
    "        round_accuracy_avg = round_accuracy / len(s)\n",
    "        train_accuracies.append(round_loss_avg)\n",
    "        train_losses.append(round_accuracy_avg)\n",
    "\n",
    "        grad_mo = magical_gradient(clients_grad_normalized).cuda()\n",
    "\n",
    "        # distribute the gradient on the parameters\n",
    "        idx = 0\n",
    "        for name, par in model.named_parameters():\n",
    "            shape = tuple(par.data.shape)\n",
    "            tot_len = np.prod(shape).astype(int) # shape[0]*shape[1]\n",
    "            par.grad = grad_mo[idx:(idx + tot_len)].reshape(shape).to(torch.float) # setting the gradients!\n",
    "\n",
    "            idx += tot_len\n",
    "\n",
    "        server_optimizer.step()\n",
    "\n",
    "        wandb.log({'train/acc': round_accuracy_avg, 'train/loss': round_loss_avg, 'round': t})\n",
    "\n",
    "        if t % test_freq == 0 or t == params['rounds']-1:\n",
    "            acc, loss = test(model)\n",
    "            test_accuracies.append(acc)\n",
    "            test_losses.append(loss)\n",
    "            wandb.log({'acc': acc, 'loss': loss, 'round': t})\n",
    "\n",
    "    return test_accuracies, test_losses\n",
    "\n",
    "\n",
    "train(model, params)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ka96RtMKQP19"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1288fecee38c44c5be5c626c4d83dbfb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14489bc6b84f46839d1398c4e23f5001": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9f10ca884164dfabc89f77b4310f0fa",
      "placeholder": "​",
      "style": "IPY_MODEL_45cc15f7ffe2483eb8bff06634fdaaa5",
      "value": "0.021 MB of 0.021 MB uploaded\r"
     }
    },
    "24beb4f068484d61a0c5213f73ae43d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45cc15f7ffe2483eb8bff06634fdaaa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7973b9bc3a64446cadd1dd22ef432ce0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14489bc6b84f46839d1398c4e23f5001",
       "IPY_MODEL_d60fae4b1f3b4fbd961c051e020ba102"
      ],
      "layout": "IPY_MODEL_1288fecee38c44c5be5c626c4d83dbfb"
     }
    },
    "b9f10ca884164dfabc89f77b4310f0fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d60fae4b1f3b4fbd961c051e020ba102": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24beb4f068484d61a0c5213f73ae43d1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db724347ab3040008122494925b38fd9",
      "value": 1
     }
    },
    "db724347ab3040008122494925b38fd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
