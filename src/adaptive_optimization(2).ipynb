{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIx5WEaJuM5I"
      },
      "source": [
        "Paper: https://arxiv.org/abs/2003.00295"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PSmFOKMBMTjP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.ops import MLP\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR100, MNIST\n",
        "from torch.optim import SGD\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWh1Xx1WqXbk"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "viVq7PLXnRkI"
      },
      "outputs": [],
      "source": [
        "K = 100\n",
        "S = np.array(range(K))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoAZ8gOdacB5",
        "outputId": "26ee7353-7b50-4d18-b899-a046a23b1215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to datasets/cifar100/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169001437/169001437 [00:03<00:00, 53558421.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting datasets/cifar100/cifar-100-python.tar.gz to datasets/cifar100\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.RandomCrop((24, 24)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR100('datasets/cifar100', train=True, transform=preprocess, download=True)\n",
        "test_dataset = CIFAR100('datasets/cifar100', train=False, transform=preprocess, download=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YLGe_BkJ2YdR"
      },
      "outputs": [],
      "source": [
        "iid = True\n",
        "samples_per_client = int(len(train_dataset) / K)\n",
        "shards_per_client = 2\n",
        "\n",
        "def split_data(dataset, iid=True):\n",
        "    if iid:\n",
        "        return torch.utils.data.random_split(train_dataset, [samples_per_client] * K)\n",
        "    else:\n",
        "        sorted_dataset = sorted(train_dataset, key=lambda x: x[1])\n",
        "        shard_size = int(samples_per_client / shards_per_client)\n",
        "        shards = [\n",
        "            torch.utils.data.Subset(\n",
        "                sorted_dataset,\n",
        "                range(i*shard_size, (i+1)*shard_size)\n",
        "            )\n",
        "            for i in range(K*shards_per_client)\n",
        "        ]\n",
        "\n",
        "        random.shuffle(shards)\n",
        "\n",
        "        return [\n",
        "            torch.utils.data.ConcatDataset([shards[2*i], shards[2*i+1]])\n",
        "            for i in range(K)\n",
        "        ]\n",
        "\n",
        "\n",
        "client_datasets = split_data(train_dataset, iid)\n",
        "assert len(client_datasets) == K\n",
        "assert len(client_datasets[0]) == samples_per_client\n",
        "assert iid or all([0 < len(set(map(lambda x: x[1], client_datasets[i]))) <= 4 for i in range(K)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMCoMOlAqhoy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCFyReyRRmzH",
        "outputId": "32825e28-7766-40dc-f9e0-5ce1780d7e8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False).cuda()\n",
        "model.fc = nn.Linear(512, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8gzjnPIqpCy"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pD_OTrI6qoMR"
      },
      "outputs": [],
      "source": [
        "def reduce_w(w_list, f):\n",
        "    return OrderedDict([\n",
        "            (key, f([x[key] for x in w_list])) for key in w_list[0].keys()\n",
        "        ])\n",
        "\n",
        "\n",
        "def fed_adagrad(v, delta, params):\n",
        "    delta_norm2 = torch.square(torch.norm(delta))\n",
        "    return v + delta_norm2\n",
        "\n",
        "\n",
        "def fed_yogi(v, delta, params):\n",
        "    delta_norm2 = torch.square(torch.norm(delta))\n",
        "    return v - (1-params['beta2']) * delta_norm2 * torch.sign(v - delta_norm2)\n",
        "\n",
        "\n",
        "def fed_adam(v, delta, params):\n",
        "    delta_norm2 = torch.square(torch.norm(delta))\n",
        "    return params['beta2'] * v + (1-params['beta2']) * delta_norm2\n",
        "\n",
        "\n",
        "methods = {\n",
        "    'adagrad': fed_adagrad,\n",
        "    'yogi': fed_yogi,\n",
        "    'adam': fed_adam\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3HCdQRYqe5f"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9RNbgaj0TNS4"
      },
      "outputs": [],
      "source": [
        "T = 300\n",
        "test_freq = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUnGzbKJZscB"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "def test(model):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    test_accuracy = 100. * correct / total\n",
        "    print(f'Test Loss: {test_loss:.6f} Acc: {test_accuracy:.2f}%')\n",
        "    return test_accuracy\n",
        "\n",
        "\n",
        "def client_update(model, k, w, params):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=params['lr_client'])\n",
        "    loader = DataLoader(client_datasets[k], batch_size=params['B'])\n",
        "\n",
        "    for i in range(params['E']):\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model.state_dict()\n",
        "\n",
        "\n",
        "def train(model, params):\n",
        "    accuracies = []\n",
        "    v = 0\n",
        "    w = model.state_dict()\n",
        "    m = reduce_w([w], lambda x: torch.mul(x[0], 0.0))\n",
        "    for t in tqdm(range(T)):\n",
        "        m = int(max(params['C']*K, 1))\n",
        "        s = np.random.choice(S, m, replace=False)\n",
        "\n",
        "        w_clients = []\n",
        "        for k in s:\n",
        "            w_clients.append(client_update(copy.deepcopy(model), k, w, params))\n",
        "\n",
        "        deltas = [\n",
        "            reduce_w(\n",
        "                [w, w_client],\n",
        "                lambda x: x[0] - x[1]\n",
        "            ) for w_client in w_clients\n",
        "        ]\n",
        "\n",
        "        n_weights = [len(client_datasets[k])/len(w_clients) for k in s]\n",
        "        delta = reduce_w(\n",
        "            [w, deltas],\n",
        "            lambda x: torch.bmm(n_weights, deltas)\n",
        "        )\n",
        "\n",
        "        # fed avg\n",
        "        # w = reduce_w(w_clients, lambda x: torch.sum(x) / len(w_clients))\n",
        "\n",
        "        m = reduce_w(\n",
        "            [m, delta],\n",
        "            lambda x: params['beta1'] * x[0] + (1-params['beta1']) * x[1]\n",
        "        )\n",
        "        v = methods[params['method']](v, delta, params)\n",
        "        w = reduce_w(\n",
        "            [w, v],\n",
        "            lambda x: x[0] + params['lr_server'] * m / (math.sqrt(v) + params['tau'])\n",
        "        )\n",
        "\n",
        "        model.load_state_dict(w)\n",
        "\n",
        "        if t % test_freq == 0 or t == T-1:\n",
        "            accuracies.append(test(model))\n",
        "\n",
        "        return accuracies\n",
        "\n",
        "params = {\n",
        "    'C': 10 / K,\n",
        "    'B': 20,\n",
        "    'E': 1,\n",
        "    'lr_server': 1e-1,\n",
        "    'lr_client': 1e-1,\n",
        "    'method': 'adagrad',\n",
        "    'beta1': 0,\n",
        "    'beta2': 0,\n",
        "    'tau': 1e-1\n",
        "}\n",
        "\n",
        "accuracies = train(model, params)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
