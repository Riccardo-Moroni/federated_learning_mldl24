{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PSmFOKMBMTjP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.ops import MLP\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR100, CIFAR10, MNIST\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from client_selector import ClientSelector\n",
        "from data_splitter import DataSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBdVX7qmDLYh",
        "outputId": "d035e628-5c58-4dcd-9599-87dadfa11aa5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mivanludvig\u001b[0m (\u001b[33mivanludvigdev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install wandb -qU\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w816VTtsS-H",
        "outputId": "4d017cd0-5aa1-4ff6-e309-8fe5141aa96b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWh1Xx1WqXbk"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "viVq7PLXnRkI"
      },
      "outputs": [],
      "source": [
        "K = 100\n",
        "\n",
        "params = {\n",
        "    'K': K,\n",
        "    'C': 0.1,\n",
        "    'B': 64,\n",
        "    'J': 4,\n",
        "    # 'lr_server': 1e-1,\n",
        "    'lr_client': 1e-1,\n",
        "    'method': 'fedavg',\n",
        "    'tau': 1e-3,\n",
        "    # 'gamma': 5,\n",
        "    'participation': 'uniform',\n",
        "    'rounds': 2000\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoAZ8gOdacB5",
        "outputId": "648d5855-3470-4708-8ecc-808e00b62d84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.RandomCrop((28, 28)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR100('datasets/cifar100', train=True, transform=preprocess, download=True)\n",
        "test_dataset = CIFAR100('datasets/cifar100', train=False, transform=preprocess, download=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLGe_BkJ2YdR",
        "outputId": "7ae0ea28-da22-4c16-ed81-ab69bd2b4059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "samples_per_client: 500\n",
            "samples_per_label: 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 57.31it/s]\n"
          ]
        }
      ],
      "source": [
        "data_split_params = {\n",
        "    'K': K,\n",
        "    'split_method': 'non-iid',\n",
        "    'n_labels': 5\n",
        "}\n",
        "\n",
        "data_splitter = DataSplitter(data_split_params, train_dataset)\n",
        "client_datasets = data_splitter.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qkLe-hT6bbtH"
      },
      "outputs": [],
      "source": [
        "def split_train_test(d):\n",
        "  train_size = int(0.8 * len(d))\n",
        "  test_size = len(d) - train_size\n",
        "  train_dataset, test_dataset = torch.utils.data.random_split(d, [train_size, test_size])\n",
        "\n",
        "  return train_dataset, test_dataset\n",
        "\n",
        "train_test_client_datasets = [split_train_test(d) for d in client_datasets]\n",
        "train_client_datasets = [d[0] for d in train_test_client_datasets]\n",
        "test_client_datasets = [d[1] for d in train_test_client_datasets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_gzlPTDXPHaZ"
      },
      "outputs": [],
      "source": [
        "client_selector = ClientSelector(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMCoMOlAqhoy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CCFyReyRRmzH"
      },
      "outputs": [],
      "source": [
        "class LeNet5_circa(nn.Module):\n",
        "    def __init__(self):\n",
        "        super( LeNet5_circa, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(4 * 4 * 64, 384)\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.fc3 = nn.Linear(192, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.conv1(x).relu())\n",
        "        x = self.pool(self.conv2(x).relu())\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x).relu()\n",
        "        x = self.fc2(x).relu()\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "model = LeNet5_circa().cuda()\n",
        "model.to('cuda')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "PbZMyaonDdDP",
        "outputId": "3c4b777d-5adb-45c4-b09b-179c9121f2d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240618_202836-uhnswlkn</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ivanludvigdev/fl/runs/uhnswlkn' target=\"_blank\">fed mod non-iid, J=4, lr=0.1, n_labels=5</a></strong> to <a href='https://wandb.ai/ivanludvigdev/fl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ivanludvigdev/fl' target=\"_blank\">https://wandb.ai/ivanludvigdev/fl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ivanludvigdev/fl/runs/uhnswlkn' target=\"_blank\">https://wandb.ai/ivanludvigdev/fl/runs/uhnswlkn</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ivanludvigdev/fl/runs/uhnswlkn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f82cda9d390>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(\n",
        "    project='fl',\n",
        "    name=f'fed mod {data_split_params[\"split_method\"]}, J={params[\"J\"]}, lr={params[\"lr_client\"]}, n_labels={data_split_params[\"n_labels\"]}',\n",
        "    config={**params, **data_split_params}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScpzaCYmLMJp",
        "outputId": "1a9a52a8-2fef-4901-dca5-c791b0a1fd60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LeNet5_circa(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=1024, out_features=384, bias=True)\n",
              "  (fc2): Linear(in_features=384, out_features=192, bias=True)\n",
              "  (fc3): Linear(in_features=192, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = lambda t: f'/content/drive/My Drive/fl/{data_split_params[\"split_method\"]}-mod-J{params[\"J\"]}-lr{params[\"lr_client\"]}-n_labels{data_split_params[\"n_labels\"]}-{t}.pt'\n",
        "\n",
        "backup = 0\n",
        "if backup:\n",
        "    model.load_state_dict(torch.load(path(backup)))\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8gzjnPIqpCy"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pD_OTrI6qoMR"
      },
      "outputs": [],
      "source": [
        "def reduce_w(w_list, f):\n",
        "    return OrderedDict([\n",
        "            (key, f([x[key] for x in w_list])) for key in w_list[0].keys()\n",
        "        ])\n",
        "\n",
        "\n",
        "def tensor_sum(tensors_list, weights=None):\n",
        "    if weights:\n",
        "      return torch.sum(torch.stack([t*w for t, w in zip(tensors_list, weights)]), dim=0)\n",
        "    return torch.sum(torch.stack(tensors_list), dim=0)\n",
        "\n",
        "\n",
        "def w_norm2(w):\n",
        "    res = 0\n",
        "    for key in w.keys():\n",
        "        res += torch.linalg.vector_norm(w[key]) ** 2\n",
        "    return math.sqrt(res)\n",
        "\n",
        "\n",
        "def fed_adagrad(v, delta, params):\n",
        "    delta_norm2 = w_norm2(delta)\n",
        "    return v + delta_norm2\n",
        "\n",
        "\n",
        "def fed_yogi(v, delta, params):\n",
        "    delta_norm2 = w_norm2(delta)\n",
        "    return v - (1-params['beta2']) * delta_norm2 * torch.sign(v - delta_norm2)\n",
        "\n",
        "\n",
        "def fed_adam(v, delta, params):\n",
        "    delta_norm2 = w_norm2(delta)\n",
        "    return params['beta2'] * v + (1-params['beta2']) * delta_norm2\n",
        "\n",
        "\n",
        "methods = {\n",
        "    'adagrad': fed_adagrad,\n",
        "    'yogi': fed_yogi,\n",
        "    'adam': fed_adam\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3HCdQRYqe5f"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9RNbgaj0TNS4"
      },
      "outputs": [],
      "source": [
        "T = params['rounds']\n",
        "test_freq = 50\n",
        "save_freq = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUnGzbKJZscB",
        "outputId": "5c4b88b0-1393-4fa8-e07e-29e892118a60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "  0%|          | 1/2000 [00:05<3:09:47,  5.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 4.605740 Acc: 1.27%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 51/2000 [00:20<1:05:48,  2.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 4.592994 Acc: 1.89%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 101/2000 [00:33<52:28,  1.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 4.511084 Acc: 2.11%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 151/2000 [00:47<50:35,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 4.424550 Acc: 2.63%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 201/2000 [01:01<55:23,  1.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 4.481052 Acc: 3.13%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 251/2000 [01:16<1:01:04,  2.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 4.223954 Acc: 4.89%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 301/2000 [01:29<46:39,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 4.177453 Acc: 5.20%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 351/2000 [01:42<44:23,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 4.058074 Acc: 6.54%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 401/2000 [01:55<40:13,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.936386 Acc: 9.08%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 451/2000 [02:08<36:02,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.911915 Acc: 9.02%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 501/2000 [02:20<32:07,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.813553 Acc: 10.67%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 551/2000 [02:33<30:28,  1.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.742543 Acc: 11.63%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 601/2000 [02:45<29:29,  1.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.712796 Acc: 11.63%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 651/2000 [02:59<29:13,  1.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.640003 Acc: 13.62%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 701/2000 [03:11<27:56,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.503747 Acc: 15.53%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 751/2000 [03:24<27:10,  1.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.555487 Acc: 14.77%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 801/2000 [03:38<25:45,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.506569 Acc: 14.87%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 851/2000 [03:51<24:59,  1.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.356865 Acc: 18.66%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 901/2000 [04:04<23:56,  1.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.319912 Acc: 19.61%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 951/2000 [04:17<24:35,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.315273 Acc: 19.96%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1001/2000 [04:30<25:05,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.289889 Acc: 19.89%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 1051/2000 [04:43<24:39,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.300867 Acc: 18.98%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 1101/2000 [04:56<24:46,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.191100 Acc: 21.93%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 1151/2000 [05:10<23:39,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.140942 Acc: 22.54%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1201/2000 [05:24<22:39,  1.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.232154 Acc: 20.87%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 1251/2000 [05:37<20:59,  1.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.038176 Acc: 25.23%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 1301/2000 [05:51<19:10,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.059211 Acc: 25.15%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 1351/2000 [06:04<17:48,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.072062 Acc: 23.56%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 1401/2000 [06:17<15:33,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.985109 Acc: 26.35%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 1451/2000 [06:30<13:43,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.011678 Acc: 25.12%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 1501/2000 [06:44<12:11,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.071455 Acc: 24.61%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 1551/2000 [06:57<10:17,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.032217 Acc: 25.28%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 1601/2000 [07:10<08:27,  1.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.912180 Acc: 27.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 1651/2000 [07:22<07:33,  1.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.906576 Acc: 27.97%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 1701/2000 [07:35<06:31,  1.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.919141 Acc: 27.60%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 1751/2000 [07:48<05:20,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.908475 Acc: 28.46%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 1801/2000 [08:01<04:16,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.858901 Acc: 28.46%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 1851/2000 [08:14<03:11,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.823965 Acc: 29.57%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 1901/2000 [08:26<02:08,  1.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.908374 Acc: 28.10%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 1951/2000 [08:39<01:04,  1.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.887194 Acc: 28.80%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [08:52<00:00,  3.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.925799 Acc: 28.24%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def test(model, loader, verbose=False):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    test_loss = test_loss / len(loader)\n",
        "    test_accuracy = 100. * correct / total\n",
        "    if verbose:\n",
        "        print(f'Test Loss: {test_loss:.6f} Acc: {test_accuracy:.2f}%')\n",
        "    return test_accuracy, test_loss\n",
        "\n",
        "\n",
        "def client_update(model, k, params):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=params['lr_client'], weight_decay=4e-4)\n",
        "    loader = DataLoader(train_client_datasets[k], batch_size=params['B'], shuffle=True)\n",
        "    test_client_loader = DataLoader(test_client_datasets[k], batch_size=params['B'], shuffle=True)\n",
        "\n",
        "    i = 0\n",
        "    for i in range(params['J']):\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            i += 1\n",
        "\n",
        "            if i >= params['J']:\n",
        "              return model.state_dict(), *test(model, test_client_loader)\n",
        "\n",
        "    return model.state_dict(), *test(model, test_client_loader)\n",
        "\n",
        "\n",
        "def train(model, params):\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "    v = params['tau'] ** 2\n",
        "    w = model.state_dict()\n",
        "    m = reduce_w([w], lambda x: torch.mul(x[0], 0.0))\n",
        "    for t in tqdm(range(T)):\n",
        "        s = client_selector.sample()\n",
        "\n",
        "        w_clients = []\n",
        "        w_losses = []\n",
        "        for k in s:\n",
        "            client_w, client_acc, client_loss = client_update(copy.deepcopy(model), k, params)\n",
        "            w_clients.append(client_w)\n",
        "            w_losses.append(client_loss)\n",
        "\n",
        "        w_sum = sum(w_losses)\n",
        "        weights = [l/w_sum for l in w_losses]\n",
        "        if params['method'] == 'fedavg':\n",
        "            w = reduce_w(\n",
        "                w_clients,\n",
        "                lambda x: tensor_sum(x, weights)\n",
        "            )\n",
        "        else:\n",
        "            deltas = [\n",
        "                reduce_w(\n",
        "                    [w, w_client],\n",
        "                    lambda x: x[1] - x[0]\n",
        "                ) for w_client in w_clients\n",
        "            ]\n",
        "\n",
        "            delta = reduce_w(\n",
        "                deltas,\n",
        "                lambda x: tensor_sum(x) / len(deltas)\n",
        "            )\n",
        "\n",
        "            m = reduce_w(\n",
        "                [m, delta],\n",
        "                lambda x: params['beta1'] * x[0] + (1-params['beta1']) * x[1]\n",
        "            )\n",
        "\n",
        "            v = methods[params['method']](v, delta, params)\n",
        "            w = reduce_w(\n",
        "                [w, m],\n",
        "                lambda x: x[0] + params['lr_server'] * x[1] / (math.sqrt(v) + params['tau'])\n",
        "            )\n",
        "\n",
        "        model.load_state_dict(w)\n",
        "\n",
        "        if t % test_freq == 0 or t == T-1:\n",
        "            acc, loss = test(model, test_loader, True)\n",
        "            accuracies.append(acc)\n",
        "            losses.append(loss)\n",
        "            wandb.log({'acc': acc, 'loss': loss, 'round': t})\n",
        "\n",
        "        if t % save_freq == 0 or t == T-1:\n",
        "            torch.save(model.state_dict(), path(t))\n",
        "\n",
        "    return accuracies, losses\n",
        "\n",
        "\n",
        "accuracies, losses = train(model, params)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jB4uZhMYe0nO"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
