{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdad1fc-75a6-49a1-903f-415787186c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "from torch.utils.data import TensorDataset\n",
    "import random\n",
    "from shakespeare_utils import shakespeare_data_pruning, tokenize_encode, concat_dict_values\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from CharRNN import CharRNN\n",
    "\n",
    "import sys\n",
    "sys.path.append('../') # necessary to import from parant directory\n",
    "from client_selector import ClientSelector\n",
    "\n",
    "# import wandb\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aae952-8d3d-4b7a-9428-9954dc99a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "K = 100\n",
    "\n",
    "params = {\n",
    "    'K': K,\n",
    "    'C': 0.3,\n",
    "    'B': 100,\n",
    "    'J': 8,\n",
    "    # 'lr_server': 1e-1,\n",
    "    'lr_client': 5e-1,\n",
    "    'method': 'fedavg',\n",
    "    'tau': 1e-3,\n",
    "    'gamma': 0.1,\n",
    "    'participation': 'uniform',\n",
    "    'rounds': 2000\n",
    "}\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from client_selector import ClientSelector\n",
    "\n",
    "client_selector = ClientSelector(params)\n",
    "\n",
    "# wandb.init(\n",
    "#     project='fl',\n",
    "#     name=f'federated_shakespeare',\n",
    "#     config= params\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe25861-4b64-460b-b191-4a7203850679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "json_train_path = '../../datasets/shakespeare/train/all_data_niid_0_keep_0_train_9.json'\n",
    "json_test_path = '../../datasets/shakespeare/test/all_data_niid_0_keep_0_test_9.json'\n",
    "\n",
    "X_train_pruned, Y_train_pruned, X_test_pruned, Y_test_pruned = shakespeare_data_pruning(json_train_path, json_test_path, crop_amount=3000)\n",
    "# data is already  split at this point {user1:[2000],...,user100:[2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c9495a-233a-4d87-9b2f-f81c4d8bfbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# define dictionary and chart to int mapping\n",
    "train_sentence = ' '.join(' '.join(single_user_list) for single_user_list in X_train_pruned.values())\n",
    "vocab = sorted(set(train_sentence))\n",
    "vocab.append('<OOV>')\n",
    "char_to_idx = {char: idx for idx, char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18531709-13b6-47d3-b977-2105e8ff39a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 40.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3000, 80]) torch.Size([100, 3000])\n",
      "torch.Size([110538, 80]) torch.Size([110538])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# from dict to nested list\n",
    "X_train_list = [X_train_pruned[key] for key in sorted(X_train_pruned.keys())]\n",
    "Y_train_list = [Y_train_pruned[key] for key in sorted(Y_train_pruned.keys())]\n",
    "\n",
    "X_train_enc, Y_train_enc, X_test_enc, Y_test_enc = [],[],[],[]\n",
    "for user in tqdm(range(len(X_train_list))):\n",
    "    X_train_enc.append(tokenize_encode(X_train_list[user], vocab, char_to_idx))\n",
    "    Y_train_enc.append(tokenize_encode(Y_train_list[user], vocab, char_to_idx))\n",
    "\n",
    "# We can discard the information about the user for the test data, since the testing is centralized \n",
    "X_test_concat = concat_dict_values(X_test_pruned)\n",
    "Y_test_concat = concat_dict_values(Y_test_pruned)\n",
    "X_test_enc = np.array(tokenize_encode(X_test_concat, vocab, char_to_idx)) # (100, 2000, 80) \n",
    "Y_test_enc = np.array(tokenize_encode(Y_test_concat, vocab, char_to_idx)).squeeze(-1) # (100, 2000, 1) --> (100, 2000,)\n",
    "\n",
    "# to tensor\n",
    "X_train_tensor = torch.tensor(X_train_enc, dtype=torch.long) # (100, 2000, 80)\n",
    "Y_train_tensor = torch.tensor(Y_train_enc, dtype=torch.long).squeeze(-1) # (100, 2000, 1) --> (100, 2000,)\n",
    "X_test_tensor = torch.tensor(X_test_enc, dtype=torch.long)\n",
    "Y_test_tensor = torch.tensor(Y_test_enc, dtype=torch.long)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100)\n",
    "\n",
    "print(X_train_tensor.shape, Y_train_tensor.shape)\n",
    "print(X_test_tensor.shape, Y_test_tensor.shape)\n",
    "\n",
    "# train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "\n",
    "train_datasets = []\n",
    "for k in range(K):\n",
    "    X_k = X_train_tensor[k]\n",
    "    Y_k = Y_train_tensor[k]\n",
    "    train_datasets.append(TensorDataset(X_k, Y_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc2f13-9260-492c-9b0c-f246ce61bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# utils\n",
    "def reduce_w(w_list, f):\n",
    "    return OrderedDict([\n",
    "            (key, f([x[key] for x in w_list])) for key in w_list[0].keys()\n",
    "        ])\n",
    "\n",
    "\n",
    "def tensor_sum(tensors_list):\n",
    "    return torch.sum(torch.stack(tensors_list), dim=0)\n",
    "\n",
    "\n",
    "def w_norm2(w):\n",
    "    res = 0\n",
    "    for key in w.keys():\n",
    "        res += torch.linalg.vector_norm(w[key]) ** 2\n",
    "    return math.sqrt(res)\n",
    "\n",
    "\n",
    "def fed_adagrad(v, delta, params):\n",
    "    delta_norm2 = w_norm2(delta)\n",
    "    return v + delta_norm2\n",
    "\n",
    "\n",
    "def fed_yogi(v, delta, params):\n",
    "    delta_norm2 = w_norm2(delta)\n",
    "    return v - (1-params['beta2']) * delta_norm2 * torch.sign(v - delta_norm2)\n",
    "\n",
    "\n",
    "def fed_adam(v, delta, params):\n",
    "    delta_norm2 = w_norm2(delta)\n",
    "    return params['beta2'] * v + (1-params['beta2']) * delta_norm2\n",
    "\n",
    "\n",
    "methods = {\n",
    "    'adagrad': fed_adagrad,\n",
    "    'yogi': fed_yogi,\n",
    "    'adam': fed_adam\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2808d-c5d0-4db1-9b03-39f168afc9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "model_params = {\n",
    "    'vocab_size' : len(vocab),\n",
    "    'embed_dim' : 8,\n",
    "    'lstm_units' : 256,\n",
    "}\n",
    "model = CharRNN(vocab_size = model_params['vocab_size'], embed_dim = model_params['embed_dim'], lstm_units=model_params['lstm_units']).cuda()\n",
    "model.to('cuda')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = SGD(model.parameters(), lr=params['lr_client'], weight_decay=4e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ab60c-8ec2-4a1b-9959-ec9898898b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "test_freq = 50\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = 100. * correct / total\n",
    "    print(f'Test Loss: {test_loss:.6f} Acc: {test_accuracy:.2f}%')\n",
    "    return test_accuracy, test_loss\n",
    "\n",
    "def client_update(model, k, params):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=params['lr_client'], weight_decay=4e-4)\n",
    "    loader = DataLoader(train_datasets[k], batch_size=params['B'], shuffle=True)\n",
    "    \n",
    "    client_loss, client_correct, client_total = 0, 0, 0\n",
    "    i = 0\n",
    "    for i in range(params['J']):\n",
    "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            client_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            client_total += targets.size(0)\n",
    "            client_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            i += 1\n",
    "\n",
    "            if i >= params['J']:\n",
    "                client_loss = client_loss / params['J']\n",
    "                client_accuracy = 100. * client_correct / client_total\n",
    "\n",
    "                return model.state_dict(), client_accuracy, client_loss\n",
    "            \n",
    "    client_loss = client_loss / params['J'] # average loss in J steps \n",
    "    client_accuracy = 100. * client_correct / client_total\n",
    "\n",
    "    return model.state_dict(), client_accuracy, client_loss\n",
    "\n",
    "def train(model, params):\n",
    "    test_accuracies, test_losses = [], []\n",
    "    train_accuracies, train_losses = [], []\n",
    "    v = params['tau'] ** 2\n",
    "    w = model.state_dict()\n",
    "    m = reduce_w([w], lambda x: torch.mul(x[0], 0.0))\n",
    "    for t in range(params['rounds']):\n",
    "        round_loss, round_accuracy = 0, 0\n",
    "        s = client_selector.sample()\n",
    "        # print(sorted(s))\n",
    "        w_clients = []\n",
    "\n",
    "        for k in s:\n",
    "            update, client_accuracy, client_loss = client_update(copy.deepcopy(model), k, params)\n",
    "            w_clients.append(update)\n",
    "            round_loss += client_loss\n",
    "            round_accuracy += client_accuracy\n",
    "        round_loss_avg = round_loss / len(s)\n",
    "        round_accuracy_avg = round_accuracy / len(s)\n",
    "        train_accuracies.append(round_loss_avg)\n",
    "        train_losses.append(round_accuracy_avg)\n",
    "\n",
    "        if params['method'] == 'fedavg':\n",
    "            w = reduce_w(\n",
    "                w_clients,\n",
    "                lambda x: tensor_sum(x) / len(w_clients)\n",
    "            )\n",
    "        else:\n",
    "            deltas = [\n",
    "                reduce_w(\n",
    "                    [w, w_client],\n",
    "                    lambda x: x[1] - x[0]\n",
    "                ) for w_client in w_clients\n",
    "            ]\n",
    "\n",
    "            delta = reduce_w(\n",
    "                deltas,\n",
    "                lambda x: tensor_sum(x) / len(deltas)\n",
    "            )\n",
    "\n",
    "            m = reduce_w(\n",
    "                [m, delta],\n",
    "                lambda x: params['beta1'] * x[0] + (1-params['beta1']) * x[1]\n",
    "            )\n",
    "\n",
    "            v = methods[params['method']](v, delta, params)\n",
    "            w = reduce_w(\n",
    "                [w, m],\n",
    "                lambda x: x[0] + params['lr_server'] * x[1] / (math.sqrt(v) + params['tau'])\n",
    "            )\n",
    "        \n",
    "        model.load_state_dict(w)\n",
    "        print(f'Train Loss: {round_loss_avg:.6f} Acc: {round_accuracy_avg:.2f}%')\n",
    "\n",
    "        if t % test_freq == 0 or t == params['rounds']-1:\n",
    "            acc, loss = test(model)\n",
    "            test_accuracies.append(acc)\n",
    "            test_losses.append(loss)\n",
    "            # wandb.log({'acc': acc, 'loss': loss, 'round': t})\n",
    "\n",
    "        # acc, loss = test(model)\n",
    "        # test_accuracies.append(acc)\n",
    "        # test_losses.append(loss)\n",
    "        # wandb.log({'acc': acc, 'loss': loss, 'round': t})\n",
    "    \n",
    "    return test_accuracies, test_losses, train_accuracies, train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c1a7df-a513-437a-9760-183237334894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.184950 Acc: 0.62%\n",
      "Test Loss: 3.977705 Acc: 18.98%\n",
      "Train Loss: 3.771400 Acc: 0.61%\n",
      "Train Loss: 3.346113 Acc: 0.61%\n",
      "Train Loss: 3.222066 Acc: 0.56%\n",
      "Train Loss: 3.220766 Acc: 0.61%\n",
      "Train Loss: 3.173524 Acc: 0.56%\n",
      "Train Loss: 3.181838 Acc: 0.51%\n",
      "Train Loss: 3.162205 Acc: 0.60%\n",
      "Train Loss: 3.168120 Acc: 0.56%\n",
      "Train Loss: 3.156507 Acc: 0.55%\n",
      "Train Loss: 3.157889 Acc: 0.62%\n",
      "Train Loss: 3.163447 Acc: 0.66%\n",
      "Train Loss: 3.162301 Acc: 0.53%\n",
      "Train Loss: 3.154746 Acc: 0.59%\n",
      "Train Loss: 3.149802 Acc: 0.58%\n",
      "Train Loss: 3.159262 Acc: 0.62%\n",
      "Train Loss: 3.157393 Acc: 0.62%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\data-science\\courses\\mldl24\\federated_learning_project\\federated_learning_mldl24\\src\\shakespeare\\federated_shakespeare.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m accuracies, losses \u001b[39m=\u001b[39m train(model, params)\n",
      "File \u001b[1;32md:\\data-science\\courses\\mldl24\\federated_learning_project\\federated_learning_mldl24\\src\\shakespeare\\federated_shakespeare.py:74\u001b[0m\n\u001b[0;32m     71\u001b[0m w_clients \u001b[39m=\u001b[39m []\n\u001b[0;32m     73\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m s:\n\u001b[1;32m---> 74\u001b[0m     update, client_accuracy, client_loss \u001b[39m=\u001b[39m client_update(copy\u001b[39m.\u001b[39;49mdeepcopy(model), k, params)\n\u001b[0;32m     75\u001b[0m     w_clients\u001b[39m.\u001b[39mappend(update)\n\u001b[0;32m     76\u001b[0m     round_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m client_loss\n",
      "File \u001b[1;32md:\\data-science\\courses\\mldl24\\federated_learning_project\\federated_learning_mldl24\\src\\shakespeare\\federated_shakespeare.py:46\u001b[0m\n\u001b[0;32m     43\u001b[0m client_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     44\u001b[0m client_correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m predicted\u001b[39m.\u001b[39meq(targets)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m---> 46\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     47\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     48\u001b[0m i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\franc\\anaconda3\\envs\\fed_learn\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\franc\\anaconda3\\envs\\fed_learn\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\franc\\anaconda3\\envs\\fed_learn\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[39m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[39mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "accuracies, losses = train(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cae240-8515-492f-ac66-a19fba9e49aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "plt.xlabel('rounds')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(accuracies, label=params['method'], marker='')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
